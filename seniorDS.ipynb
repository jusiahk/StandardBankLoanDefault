{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jusiahk/StandardBankLoanDefault/blob/master/seniorDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156a81eb-a96f-4bec-89c8-b51a1fcc3f79",
      "metadata": {
        "id": "156a81eb-a96f-4bec-89c8-b51a1fcc3f79"
      },
      "source": [
        "Problem: How can we grade clients by there credit scores to determine there credit risk/worthiness.\n",
        "\n",
        "Solution: Creadit Score Card to manage, determine a borrower who is able to pay back there loan before 60 days elapse. (Credit Score) is an assessment of the relative likelihood of a certain credit event occurring, given a number of observable inputs.\n",
        "\n",
        "Can be used to decide whether a client's credit application is accepted or rejected basing on there 3 credit score figure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b49b9d9-396c-4eed-acfa-b3c38653fccb",
      "metadata": {
        "id": "5b49b9d9-396c-4eed-acfa-b3c38653fccb"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split,RepeatedStratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed40c969-fcf5-477e-b30f-85a6beb9ad37",
      "metadata": {
        "id": "ed40c969-fcf5-477e-b30f-85a6beb9ad37"
      },
      "source": [
        "Explanatory Data Analysis  & Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b95cfb5-ea17-4927-a5a2-d260211bbc77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "7b95cfb5-ea17-4927-a5a2-d260211bbc77",
        "outputId": "b44e8b8b-43a0-4dec-9b44-ffedafd5a164"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-551c46d5cb26>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/hp/Desktop/noahk - Copy.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/hp/Desktop/noahk - Copy.xlsx'"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_excel('C:/Users/hp/Desktop/noahk - Copy.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf1c117-ebe4-40d2-9f07-c65bd16f4445",
      "metadata": {
        "id": "ecf1c117-ebe4-40d2-9f07-c65bd16f4445"
      },
      "outputs": [],
      "source": [
        "df = data\n",
        "df.shape # shape of the complete dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc51603-9171-4ef3-b0fa-db84a91d81a0",
      "metadata": {
        "id": "ccc51603-9171-4ef3-b0fa-db84a91d81a0"
      },
      "outputs": [],
      "source": [
        "#Let's start by examining the structure of the dataset\n",
        "print(\"Dataset shape:\", data.shape)\n",
        "print(\"Columns:\", data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631fe333-29fa-4e79-9e9a-5cda3ad3b21d",
      "metadata": {
        "id": "631fe333-29fa-4e79-9e9a-5cda3ad3b21d"
      },
      "outputs": [],
      "source": [
        "df.isna().sum() # checking for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576901d6-a298-4e95-8362-969450535e80",
      "metadata": {
        "id": "576901d6-a298-4e95-8362-969450535e80"
      },
      "outputs": [],
      "source": [
        "#lets check and treat any duplicates.\n",
        "df.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb263309-c910-458b-8ca4-4786466c5e58",
      "metadata": {
        "id": "bb263309-c910-458b-8ca4-4786466c5e58"
      },
      "outputs": [],
      "source": [
        "#Checking for dupplicates\n",
        "# Identify duplicate rows across all columns\n",
        "duplicates = df[df.duplicated(keep='first')]\n",
        "\n",
        "# Drop the duplicate rows, keeping the first occurrence\n",
        "df.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "# Append one occurrence of each duplicate back to the DataFrame\n",
        "df = df.append(duplicates.head(1))\n",
        "\n",
        "# Reset the index of the modified DataFrame\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1a3626-447a-4443-ba89-0ba5f9a1ee43",
      "metadata": {
        "id": "9a1a3626-447a-4443-ba89-0ba5f9a1ee43"
      },
      "outputs": [],
      "source": [
        "# Re-explore the df\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03bcc7b-bd17-4f00-99ab-13782376bf24",
      "metadata": {
        "id": "d03bcc7b-bd17-4f00-99ab-13782376bf24"
      },
      "outputs": [],
      "source": [
        "df.skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c79063-a5b3-493c-b024-f4ac31cfd77b",
      "metadata": {
        "id": "62c79063-a5b3-493c-b024-f4ac31cfd77b"
      },
      "outputs": [],
      "source": [
        "df.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81af119-e96f-46c4-977d-8de66b61049d",
      "metadata": {
        "id": "f81af119-e96f-46c4-977d-8de66b61049d"
      },
      "outputs": [],
      "source": [
        "# Assuming any loan_age_day above 60 is defaulted =1 otherwise false 0 a variable is created as target variable\n",
        "data['Response'] = np.where(data['LOAN_AGE_DAYS'] > 60, 1, 0)\n",
        "# Drop the original 'loan_status' column\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a7f145-99e3-4d3b-907a-b0272d860490",
      "metadata": {
        "id": "70a7f145-99e3-4d3b-907a-b0272d860490"
      },
      "outputs": [],
      "source": [
        "#lets see the head of our dataset the 5 columns\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c4cc72-0bfb-40cc-903e-483aea8c4f72",
      "metadata": {
        "id": "87c4cc72-0bfb-40cc-903e-483aea8c4f72"
      },
      "outputs": [],
      "source": [
        "#Summary statistics of numerical columns\n",
        "df = data\n",
        "print(\"\\nSummary statistics:\")\n",
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8c279f-cd8f-40bc-b6ee-3e7c5e7c5940",
      "metadata": {
        "id": "ef8c279f-cd8f-40bc-b6ee-3e7c5e7c5940"
      },
      "outputs": [],
      "source": [
        "#let filter out for the bill values greater than 40 dollars\n",
        "df[df[\"RCVD_AMNT_ ON_WALLET\"] == 0.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8fa942-659f-4fd2-9542-cbca3aea6782",
      "metadata": {
        "id": "6b8fa942-659f-4fd2-9542-cbca3aea6782"
      },
      "outputs": [],
      "source": [
        "#let filter out for the response values greater than 60\n",
        "df[df[\"Response\"] == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc374a0-feaf-4dab-84a7-cfed7c1bd954",
      "metadata": {
        "id": "bdc374a0-feaf-4dab-84a7-cfed7c1bd954"
      },
      "source": [
        "Dealing with outliers far from the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21d9778-95c1-4196-96ef-ae74c068035e",
      "metadata": {
        "id": "c21d9778-95c1-4196-96ef-ae74c068035e"
      },
      "outputs": [],
      "source": [
        "# lets check our dataset for  outliers and normalize if any\n",
        "# Calculate z-scores for each variable\n",
        "z_scores = np.abs(stats.zscore(df))\n",
        "\n",
        "# Set a threshold for outlier detection\n",
        "threshold = 3\n",
        "\n",
        "# Identify the outliers by comparing z-scores to the threshold\n",
        "outlier_indices = np.where(z_scores > threshold)\n",
        "\n",
        "# Create a DataFrame with the outlier values\n",
        "outliers = pd.DataFrame({'Variable': df.columns[outlier_indices[1]],\n",
        "                         'Outlier Value': df.values[outlier_indices]})\n",
        "\n",
        "# Display the outlier table\n",
        "print(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01305ce-e397-481a-8013-44dfbda26f5e",
      "metadata": {
        "id": "e01305ce-e397-481a-8013-44dfbda26f5e"
      },
      "outputs": [],
      "source": [
        "#Can we normalize these as we have data withmany zeros but also helps on sparsity.\n",
        "df['LOAN_AGE_DAYS'].value_counts(normalize = True)\n",
        "df['WALLET_CREDITS'].value_counts(normalize = True)\n",
        "df['TOTAL AIRTIME LOAN'].value_counts(normalize = True)\n",
        "df['TRSF_FROM_BANK_TO_ WALLET _AMNT'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe9c0137-866d-411c-afe0-d3a241bf8ed2",
      "metadata": {
        "id": "fe9c0137-866d-411c-afe0-d3a241bf8ed2"
      },
      "source": [
        "Feature selection & Target variable Identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926a5a73-1438-4d06-adee-7f6aae252b33",
      "metadata": {
        "id": "926a5a73-1438-4d06-adee-7f6aae252b33"
      },
      "outputs": [],
      "source": [
        "# define features and labels\n",
        "features = list(df.columns.values)\n",
        "features.remove('Response')\n",
        "labels = ['Response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c390142d-2a6a-4c6a-a569-f200af8e6762",
      "metadata": {
        "id": "c390142d-2a6a-4c6a-a569-f200af8e6762"
      },
      "outputs": [],
      "source": [
        "X = df[features]\n",
        "y = df[labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b885cc44-8ea5-455b-acd0-87141feda4a1",
      "metadata": {
        "id": "b885cc44-8ea5-455b-acd0-87141feda4a1"
      },
      "outputs": [],
      "source": [
        "cor = df.corr()\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(cor, annot = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8076f6d-e1ac-46ad-9bca-f11d189ce0a6",
      "metadata": {
        "id": "f8076f6d-e1ac-46ad-9bca-f11d189ce0a6"
      },
      "source": [
        "Model Building & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94f18f1-e65d-4c24-a251-ce654bfbb1d8",
      "metadata": {
        "scrolled": true,
        "id": "c94f18f1-e65d-4c24-a251-ce654bfbb1d8"
      },
      "outputs": [],
      "source": [
        "#Machine learning models expect scaled data in range of 1 or 0 .\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2,random_state=9)\n",
        "\n",
        "pd.DataFrame(scaled_X, columns=X.columns.values).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4200da03-c2c3-469b-9e51-6a9b98050ab2",
      "metadata": {
        "id": "4200da03-c2c3-469b-9e51-6a9b98050ab2"
      },
      "source": [
        "a) The statement might be true basing on a a specific dataset. Supprisingly with ths dataset biggest percentage falls\n",
        "between 14 and 17th of the month.\n",
        "\n",
        "Though in normal cases one is advised not to imply due to any biases or miss-reprentation of data could affect performance\n",
        "hence its advised to look at a whole dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97fab0b-1cf7-44db-8170-11b228b5421f",
      "metadata": {
        "id": "a97fab0b-1cf7-44db-8170-11b228b5421f"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.bar(Counter(y_train['Response']).keys(),Counter(y_train['Response']).values())\n",
        "plt.xticks([0,1])\n",
        "plt.title('Training set')\n",
        "plt.subplot(1,2,2)\n",
        "plt.bar(Counter(y_test['Response']).keys(),Counter(y_test['Response']).values())\n",
        "plt.xticks([0,1])\n",
        "plt.title('Test set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6d0086-6bc7-454c-8ecd-bb12568104f5",
      "metadata": {
        "scrolled": true,
        "id": "8a6d0086-6bc7-454c-8ecd-bb12568104f5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the logistic regression model and weights will put into account the imbalances\n",
        "clf = LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced')\n",
        "\n",
        "# Perform cross-validation for better nodel performance\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores (Accuracy):\", scores)\n",
        "print(\"Mean Accuracy:\", scores.mean())\n",
        "\n",
        "# Fit the logistic regression model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression model accuracy (in %):\", acc * 100)\n",
        "\n",
        "# Print confusion matrix\n",
        "result = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "metrics.ConfusionMatrixDisplay(confusion_matrix=result).plot()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "result = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "acd2927f-a1b6-42d8-b0b6-b4e5bea0ebc2",
      "metadata": {
        "id": "acd2927f-a1b6-42d8-b0b6-b4e5bea0ebc2"
      },
      "source": [
        "Suprisingly in the real world it is rare to have a close matrix\n",
        "\n",
        "This means if we can have a torelence of error depending on the industry for example we rather have less incorrectly  predicted\n",
        "\n",
        "\n",
        "• True Positives: we correctly predicted they are defaulters.(1483)\n",
        "• True Negatives: we correctly predicted they are  Non defaulters.(296)\n",
        "• False Positives: we incorrectly predicted they are defaulters.(19)\n",
        "• False Negatives: we incorrectly predicted they are not defaulters.(0)\n",
        "\n",
        "This is where we see that the model can perform more better. In a business, there will be\n",
        "a certain tolerance towards misclassification of the negative labels (in this case 0) as positive (1).\n",
        "But misclassification of a 1 as 0 means rejecting a potential customer which is bad for the business."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94260969-ea20-442f-82e5-07f002b4fc19",
      "metadata": {
        "id": "94260969-ea20-442f-82e5-07f002b4fc19"
      },
      "source": [
        "Score Card creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d84cd5-9027-4d2d-a524-bbde253d9f9f",
      "metadata": {
        "id": "d4d84cd5-9027-4d2d-a524-bbde253d9f9f"
      },
      "outputs": [],
      "source": [
        "# Convert the numpy array back to a DataFrame\n",
        "X_test_df = pd.DataFrame(X_test, columns=['CUST_TXN_DATE', 'CUST_ID_ACCT1', 'DEPOSIT_AMNT_ON_WALLET', 'RCVD_AMNT_ON_WALLET',\n",
        "                                          'TRSF_FROM_BANK_TO_WALLET_AMNT', 'WALLET_CREDITS', 'DAYS_ARTM_LESS_UGX 2000',\n",
        "                                          'TOTAL AIRTIME LOAN', 'LOAN_AGE_DAYS'])\n",
        "\n",
        "# Extract the customer IDs from the test dataset\n",
        "cust_ids = X_test_df['CUST_ID_ACCT1']\n",
        "\n",
        "# Preprocess the test dataset by selecting relevant features and encoding categorical variables if needed\n",
        "X_test_processed = X_test_df[['CUST_TXN_DATE', 'CUST_ID_ACCT1', 'DEPOSIT_AMNT_ON_WALLET', 'RCVD_AMNT_ON_WALLET',\n",
        "                              'TRSF_FROM_BANK_TO_WALLET_AMNT', 'WALLET_CREDITS', 'DAYS_ARTM_LESS_UGX 2000',\n",
        "                              'TOTAL AIRTIME LOAN', 'LOAN_AGE_DAYS']]\n",
        "\n",
        "# Calculate credit scores using the trained model\n",
        "credit_scores = clf.predict_proba(X_test_processed)[:, 1] * 1000\n",
        "\n",
        "# Define credit score grade thresholds\n",
        "grade_thresholds = [300, 550, 800, 850]\n",
        "\n",
        "# Assign credit score grades based on thresholds\n",
        "credit_score_grades = pd.cut(credit_scores, bins=grade_thresholds, labels=['D', 'C', 'B'], right=True)\n",
        "\n",
        "\n",
        "# Create a dataframe with customer ID and credit score (without credit_score_grades)\n",
        "credit_score_df = pd.DataFrame({'CUST_ID_ACCT1': cust_ids, 'credit_score': credit_scores})\n",
        "\n",
        "# Print the credit score information\n",
        "print(credit_score_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220312ea-67f8-459c-a0a1-7267c56c55a6",
      "metadata": {
        "id": "220312ea-67f8-459c-a0a1-7267c56c55a6"
      },
      "outputs": [],
      "source": [
        "# Define the minimum and maximum scores you want\n",
        "min_score = 300\n",
        "max_score = 850\n",
        "\n",
        "# Calculate credit scores using the trained model\n",
        "credit_scores = clf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "# Rescale the credit scores to the desired range\n",
        "scaled_credit_scores = min_score + (max_score - min_score) * (credit_scores - credit_scores.min()) / (credit_scores.max() - credit_scores.min())\n",
        "\n",
        "# Convert the scaled credit scores to integers\n",
        "credit_score_df['credit_score'] = scaled_credit_scores.astype(int)\n",
        "\n",
        "# Print the credit score information\n",
        "print(credit_score_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856ef3a6-52ba-4abd-9243-9f0d9c1de89f",
      "metadata": {
        "id": "856ef3a6-52ba-4abd-9243-9f0d9c1de89f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}